{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType\n",
    "from imagebind import data\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "input_folder = '/data1/dxw_data/llm/redbook_final/script_next/combined_seg_img_pure_094'\n",
    "output_folder = '/data1/dxw_data/llm/redbook_final/script_next/combined_seg_img_pure_094_cluster_imagebind3'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda:4\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate model\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load image paths\n",
    "image_paths = [os.path.join(input_folder, fname) for fname in os.listdir(input_folder) if fname.endswith('.png')]\n",
    "\n",
    "# Function to load and transform a batch of images\n",
    "def load_images_batch(image_paths_batch):\n",
    "    images = [transform(Image.open(path).convert('RGB')) for path in image_paths_batch]\n",
    "    return torch.stack(images).to(device)\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "\n",
    "# Generate embeddings in batches\n",
    "all_embeddings = []\n",
    "for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Generating embeddings\"):\n",
    "    batch_paths = image_paths[i:i + batch_size]\n",
    "    images_tensor = load_images_batch(batch_paths)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model({ModalityType.VISION: images_tensor})\n",
    "    all_embeddings.append(embeddings[ModalityType.VISION].cpu())\n",
    "    torch.cuda.empty_cache()  # Clear cache to free memory\n",
    "\n",
    "# Concatenate all embeddings\n",
    "all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "# Determine optimal number of clusters using Average Silhouette Method\n",
    "silhouette_scores = []\n",
    "k_values = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120,150,200]  # Discrete values for k\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(all_embeddings.numpy())\n",
    "    score = silhouette_score(all_embeddings.numpy(), labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(30, 6))  # Increased width to three times the original\n",
    "plt.plot(k_values, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Average Silhouette Score')\n",
    "plt.title('Average Silhouette Score vs. Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
    "\n",
    "# Perform clustering with optimal k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "labels = kmeans.fit_predict(all_embeddings.numpy())\n",
    "\n",
    "# Save clustered images to output folders\n",
    "for idx, label in tqdm(enumerate(labels), desc=\"Saving clustered images\", total=len(labels)):\n",
    "    label_folder = os.path.join(output_folder, str(label))\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "    shutil.copy(image_paths[idx], os.path.join(label_folder, os.path.basename(image_paths[idx])))\n",
    "\n",
    "# Save labels to JSON\n",
    "labels_json = {os.path.basename(image_paths[idx]): int(label) for idx, label in enumerate(labels)}\n",
    "with open(os.path.join(output_folder, 'labels.json'), 'w') as f:\n",
    "    json.dump(labels_json, f)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "print(f'Clustering complete. Output saved to {output_folder}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Determine optimal number of clusters using Average Silhouette Method\n",
    "silhouette_scores = []\n",
    "k_values = [10,12,15,18,20,22,25,28,30,32,34,36,38,40,42,45,48,50]  # Discrete values for k\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(all_embeddings.numpy())\n",
    "    score = silhouette_score(all_embeddings.numpy(), labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(30, 6))  # Increased width to three times the original\n",
    "plt.plot(k_values, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Average Silhouette Score')\n",
    "plt.title('Average Silhouette Score vs. Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
    "\n",
    "# Perform clustering with optimal k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "labels = kmeans.fit_predict(all_embeddings.numpy())\n",
    "\n",
    "# Save clustered images to output folders\n",
    "for idx, label in tqdm(enumerate(labels), desc=\"Saving clustered images\", total=len(labels)):\n",
    "    label_folder = os.path.join(output_folder, str(label))\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "    shutil.copy(image_paths[idx], os.path.join(label_folder, os.path.basename(image_paths[idx])))\n",
    "\n",
    "# Save labels to JSON\n",
    "labels_json = {os.path.basename(image_paths[idx]): int(label) for idx, label in enumerate(labels)}\n",
    "with open(os.path.join(output_folder, 'labels.json'), 'w') as f:\n",
    "    json.dump(labels_json, f)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "print(f'Clustering complete. Output saved to {output_folder}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
