{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 200 distinct rows based on poster_id from poster_got_50w.csv and save the result in poster_test_200.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV file with rows corresponding to 50 distinct poster_id saved as 'poster_test_50.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/home/disk1/red_disk1/poster_got_50w.csv'\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select 50 distinct poster_id\n",
    "distinct_poster_ids = df['poster_id'].drop_duplicates().head(50)\n",
    "\n",
    "# Filter the DataFrame to include only rows with the selected poster_id\n",
    "filtered_rows = df[df['poster_id'].isin(distinct_poster_ids)]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "output_path = '/home/disk1/red_disk1/test/poster_test_50.csv'\n",
    "filtered_rows.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"New CSV file with rows corresponding to 50 distinct poster_id saved as 'poster_test_50.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep fashion posts only\n",
    "\n",
    "1. Filter rows containing fashion-related keywords in 'post_title' or 'post_content'\n",
    "2. Remove posts with no post_date or post_like or post_collect or post_comments\n",
    "3. Set time range from 2023-06-01 to 2024-05-31 to ensure exactly one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 distinct poster_id in the filtered data.\n",
      "There are 2494 distinct post_id in the filtered data.\n",
      "Filtered data has been saved to /home/disk1/red_disk1/test/poster_test_fashion.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the path to the CSV file\n",
    "file_path = '/home/disk1/red_disk1/test/poster_test_50.csv'\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'post_date' to datetime format\n",
    "df['post_date'] = pd.to_datetime(df['post_date'], errors='coerce')\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2023-06-01'\n",
    "end_date = '2024-05-31'\n",
    "\n",
    "# Filter rows based on the date range\n",
    "df = df[(df['post_date'] >= start_date) & (df['post_date'] <= end_date)]\n",
    "\n",
    "# Define fashion-related keywords\n",
    "fashion_keywords = [\n",
    "    \"时尚\", \"穿搭\", \"搭配\", \"潮流\", \"服装\", \"造型\", \"衣服\", \"新品\", \"裙子\", \"裤子\", \"连衣裙\", \n",
    "    \"上衣\", \"衬衫\", \"外套\", \"牛仔裤\", \"毛衣\", \"包包\", \"鞋子\", \"首饰\", \"帽子\", \"眼镜\", \"简约\", \n",
    "    \"休闲\", \"正式\", \"甜美\", \"酷\", \"时髦\", \"复古\", \"韩系\", \"日系\", \"轻奢\", \"#OOTD\", \"#Ootd\", \n",
    "    \"#ootd\", \"#时尚达人\", \"#穿搭指南\", \"#今日穿搭\", \"#潮流搭配\", \"#时尚博主\", \"#新品推荐\", \n",
    "    \"#街拍\", \"#每日穿搭\", \"#名牌\", \"夏装\", \"冬装\", \"春装\", \"秋装\", \"节日\", \"婚礼\"\n",
    "]\n",
    "\n",
    "# Create a regex pattern for the fashion keywords\n",
    "pattern = re.compile('|'.join(fashion_keywords), re.IGNORECASE)\n",
    "\n",
    "# Filter rows containing fashion-related keywords in 'post_title' or 'post_content'\n",
    "df_fashion = df[df['post_title'].str.contains(pattern, na=False) | df['post_content'].str.contains(pattern, na=False)]\n",
    "\n",
    "# Remove rows with missing information in the specified columns\n",
    "df_fashion_cleaned = df_fashion.dropna(subset=['post_date', 'post_like', 'post_collect', 'post_comments'])\n",
    "\n",
    "# Count the number of distinct poster_id and post_id\n",
    "num_distinct_poster_id = df_fashion_cleaned['poster_id'].nunique()\n",
    "num_distinct_post_id = df_fashion_cleaned['post_id'].nunique()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"There are {num_distinct_poster_id} distinct poster_id in the filtered data.\")\n",
    "print(f\"There are {num_distinct_post_id} distinct post_id in the filtered data.\")\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path = '/home/disk1/red_disk1/test/poster_test_fashion.csv'\n",
    "df_fashion_cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Filtered data has been saved to\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the data from the all_data folder based on poster_id and post_id in poster_test_fashion.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied all data for poster_id 5659a9f903eb841795e4fba9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the file paths\n",
    "csv_file_path = '/home/disk1/red_disk1/test/poster_test_fashion.csv'\n",
    "all_data_folder = '/home/disk1/red_disk1/all_data'\n",
    "output_folder = '/home/disk1/red_disk1/test/data'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Iterate over each unique poster_id\n",
    "for poster_id in df['poster_id'].unique():\n",
    "    poster_id = str(poster_id)\n",
    "    \n",
    "    # Define the source folder path\n",
    "    source_poster_folder = os.path.join(all_data_folder, poster_id)\n",
    "    \n",
    "    # Define the destination folder path\n",
    "    dest_poster_folder = os.path.join(output_folder, poster_id)\n",
    "    \n",
    "    # Check if the source folder exists\n",
    "    if os.path.exists(source_poster_folder):\n",
    "        # Copy the entire poster_id folder to the destination\n",
    "        shutil.copytree(source_poster_folder, dest_poster_folder, dirs_exist_ok=True)\n",
    "        print(f\"Copied all data for poster_id {poster_id}\")\n",
    "    else:\n",
    "        print(f\"Source folder for poster_id {poster_id} does not exist\")\n",
    "\n",
    "print(\"Data selection completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of poster_id directories in the all_data or test/data folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 177 poster_id directories in the test/data folder.\n",
      "There are 23363 distinct post_id files in the test/data folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the all_data folder\n",
    "# all_data_folder = '/home/disk1/red_disk1/all_data'\n",
    "all_data_folder = '/home/disk1/red_disk1/test/data'\n",
    "\n",
    "# Get a list of all items in the all_data folder\n",
    "all_items = os.listdir(all_data_folder)\n",
    "\n",
    "# Filter the list to include only directories (which represent poster_id)\n",
    "poster_ids = [item for item in all_items if os.path.isdir(os.path.join(all_data_folder, item))]\n",
    "\n",
    "# Count the number of poster_id directories\n",
    "num_poster_ids = len(poster_ids)\n",
    "\n",
    "# Initialize a set to store unique post_ids\n",
    "unique_post_ids = set()\n",
    "\n",
    "# Iterate through each poster_id directory to count distinct post_id files\n",
    "for poster_id in poster_ids:\n",
    "    poster_id_path = os.path.join(all_data_folder, poster_id)\n",
    "    post_files = os.listdir(poster_id_path)\n",
    "    for post_file in post_files:\n",
    "        post_id, _ = os.path.splitext(post_file)  # Extract post_id without file extension\n",
    "        unique_post_ids.add(post_id)\n",
    "\n",
    "# Count the number of distinct post_ids\n",
    "num_post_ids = len(unique_post_ids)\n",
    "\n",
    "# Print the results\n",
    "print(f\"There are {num_poster_ids} poster_id directories in the test/data folder.\")\n",
    "print(f\"There are {num_post_ids} distinct post_id files in the test/data folder.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
