{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import U2NET\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import gdown\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from collections import OrderedDict\n",
    "from options import opt\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(\"----No checkpoints at given path----\")\n",
    "        return\n",
    "    model_state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in model_state_dict.items():\n",
    "        name = k[7:]  # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print(\"----checkpoints loaded from path: {}----\".format(checkpoint_path))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_palette(num_cls):\n",
    "    \"\"\" Returns the color map for visualizing the segmentation mask.\n",
    "    Args:\n",
    "        num_cls: Number of classes\n",
    "    Returns:\n",
    "        The color map\n",
    "    \"\"\"\n",
    "    n = num_cls\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= (((lab >> 0) & 1) << (7 - i))\n",
    "            palette[j * 3 + 1] |= (((lab >> 1) & 1) << (7 - i))\n",
    "            palette[j * 3 + 2] |= (((lab >> 2) & 1) << (7 - i))\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette\n",
    "\n",
    "\n",
    "class Normalize_image(object):\n",
    "    \"\"\"Normalize given tensor into given mean and standard dev\n",
    "\n",
    "    Args:\n",
    "        mean (float): Desired mean to substract from tensors\n",
    "        std (float): Desired std to divide from tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        assert isinstance(mean, (float))\n",
    "        if isinstance(mean, float):\n",
    "            self.mean = mean\n",
    "\n",
    "        if isinstance(std, float):\n",
    "            self.std = std\n",
    "\n",
    "        self.normalize_1 = transforms.Normalize(self.mean, self.std)\n",
    "        self.normalize_3 = transforms.Normalize([self.mean] * 3, [self.std] * 3)\n",
    "        self.normalize_18 = transforms.Normalize([self.mean] * 18, [self.std] * 18)\n",
    "\n",
    "    def __call__(self, image_tensor):\n",
    "        if image_tensor.shape[0] == 1:\n",
    "            return self.normalize_1(image_tensor)\n",
    "\n",
    "        elif image_tensor.shape[0] == 3:\n",
    "            return self.normalize_3(image_tensor)\n",
    "\n",
    "        elif image_tensor.shape[0] == 18:\n",
    "            return self.normalize_18(image_tensor)\n",
    "\n",
    "        else:\n",
    "            assert \"Please set proper channels! Normlization implemented only for 1, 3 and 18\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def apply_transform(img):\n",
    "    transforms_list = []\n",
    "    transforms_list += [transforms.ToTensor()]\n",
    "    transforms_list += [Normalize_image(0.5, 0.5)]\n",
    "    transform_rgb = transforms.Compose(transforms_list)\n",
    "    return transform_rgb(img)\n",
    "\n",
    "\n",
    "\n",
    "def generate_mask(input_image, net, palette, device = 'cpu'):\n",
    "\n",
    "    #img = Image.open(input_image).convert('RGB')\n",
    "    img = input_image\n",
    "    img_size = img.size\n",
    "    img = img.resize((768, 768), Image.BICUBIC)\n",
    "    image_tensor = apply_transform(img)\n",
    "    image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "\n",
    "    alpha_out_dir = os.path.join(opt.output,'alpha')\n",
    "    cloth_seg_out_dir = os.path.join(opt.output,'cloth_seg')\n",
    "\n",
    "    os.makedirs(alpha_out_dir, exist_ok=True)\n",
    "    os.makedirs(cloth_seg_out_dir, exist_ok=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_tensor = net(image_tensor.to(device))\n",
    "        output_tensor = F.log_softmax(output_tensor[0], dim=1)\n",
    "        output_tensor = torch.max(output_tensor, dim=1, keepdim=True)[1]\n",
    "        output_tensor = torch.squeeze(output_tensor, dim=0)\n",
    "        output_arr = output_tensor.cpu().numpy()\n",
    "\n",
    "    classes_to_save = []\n",
    "\n",
    "    # Check which classes are present in the image\n",
    "    for cls in range(1, 4):  # Exclude background class (0)\n",
    "        if np.any(output_arr == cls):\n",
    "            classes_to_save.append(cls)\n",
    "\n",
    "    # Save alpha masks\n",
    "    for cls in classes_to_save:\n",
    "        alpha_mask = (output_arr == cls).astype(np.uint8) * 255\n",
    "        alpha_mask = alpha_mask[0]  # Selecting the first channel to make it 2D\n",
    "        alpha_mask_img = Image.fromarray(alpha_mask, mode='L')\n",
    "        alpha_mask_img = alpha_mask_img.resize(img_size, Image.BICUBIC)\n",
    "        alpha_mask_img.save(os.path.join(alpha_out_dir, f'{cls}.png'))\n",
    "\n",
    "    # Save final cloth segmentations\n",
    "    cloth_seg = Image.fromarray(output_arr[0].astype(np.uint8), mode='P')\n",
    "    cloth_seg.putpalette(palette)\n",
    "    cloth_seg = cloth_seg.resize(img_size, Image.BICUBIC)\n",
    "    cloth_seg.save(os.path.join(cloth_seg_out_dir, 'final_seg.png'))\n",
    "    return cloth_seg\n",
    "\n",
    "\n",
    "\n",
    "def check_or_download_model(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        url = \"https://drive.google.com/uc?id=11xTBALOeUkyuaK3l60CpkYHLTmv7k3dY\"\n",
    "        gdown.download(url, file_path, quiet=False)\n",
    "        print(\"Model downloaded successfully.\")\n",
    "    else:\n",
    "        print(\"Model already exists.\")\n",
    "\n",
    "\n",
    "def load_seg_model(checkpoint_path, device='cpu'):\n",
    "    net = U2NET(in_ch=3, out_ch=4)\n",
    "    check_or_download_model(checkpoint_path)\n",
    "    net = load_checkpoint(net, checkpoint_path)\n",
    "    net = net.to(device)\n",
    "    net = net.eval()\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists.\n",
      "----checkpoints loaded from path: /data1/dxw_data/llm/huggingface-cloth-segmentation/checkpoint/cloth_segm.pth----\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:4' \n",
    "\n",
    "# Create an instance of your model\n",
    "model = load_seg_model(\"/data1/dxw_data/llm/huggingface-cloth-segmentation/checkpoint/cloth_segm.pth\", device=device)\n",
    "\n",
    "palette = get_palette(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/14468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxw/anaconda3/envs/agent/lib/python3.8/site-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "Processing images: 100%|██████████| 14468/14468 [33:40<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Processed images saved to: /data1/dxw_data/llm/redbook_final/script_next/data_img_20%_segcloth_background\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths and parameters\n",
    "image_folder = '/data1/dxw_data/llm/redbook_final/data2/all_processed_data'\n",
    "output_folder = '/data1/dxw_data/llm/redbook_final/script_next/data_img_20%_segcloth_background'\n",
    "device = \"cuda:4\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all PNG images in the folder\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]\n",
    "# Iterate through images named in sequence like 1.png, 2.png, etc.\n",
    "i = 1\n",
    "# Iterate through all PNG images in the folder with tqdm progress bar\n",
    "for i, filename in enumerate(tqdm(image_files, desc=\"Processing images\"), 1):\n",
    "    if filename.endswith('.png'):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Process the image to generate the mask\n",
    "        cloth_seg = generate_mask(image, net=model, palette=palette, device=device)\n",
    "\n",
    "        # Save the processed mask\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cloth_seg.save(output_path)\n",
    "        # print(f\"Processed image: {filename}\")\n",
    "    # print(f\"-------------第{i}次----------------\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(\"Processing complete. Processed images saved to:\", output_folder)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
