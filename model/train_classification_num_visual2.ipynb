{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files and directories are verified to exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_308912/2173622762.py:35: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  rawdata = pd.read_csv(rawdata_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data samples: 42698\n",
      "After 2 months data samples: 43683\n",
      "Converted post_date to standard format and removed invalid dates.\n",
      "Randomly sampled 426 raw data samples.\n",
      "Filtered after 2 months data to 649 samples.\n",
      "Training raw data samples: 323\n",
      "Testing raw data samples: 103\n",
      "Training after 2 month data samples: 447\n",
      "Testing after 2 month data samples: 202\n",
      "Training after 2 month data samples after cleaning: 437\n",
      "Testing after 2 month data samples after cleaning: 202\n",
      "Number of training windows: 264\n",
      "Number of testing windows: 44\n",
      "Image transformations defined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 264/264 [15:17<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed samples: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 44/44 [02:44<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed samples: 22\n",
      "Number of training samples: 106\n",
      "Number of test samples: 22\n",
      "Number of batches in train_loader: 106\n",
      "Number of batches in test_loader: 22\n",
      "ImageBind model loaded and set to evaluation mode.\n",
      "Model architecture defined.\n",
      "Model, criterion, and optimizer initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 106/106 [01:24<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.5750053165808934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 106/106 [01:34<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 0.437958725077926\n",
      "Model training completed and saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   5%|▍         | 1/22 [00:00<00:11,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-11-21T00:00:00, Post ID: 655c80b000000000330093c0, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▉         | 2/22 [00:01<00:14,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-11-26T00:00:00, Post ID: 6562b917000000003300563e, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-31T00:00:00, Post ID: 653fec5f000000001f034cce, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  18%|█▊        | 4/22 [00:03<00:16,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-12-21T00:00:00, Post ID: 65840a5a000000000602b98c, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  23%|██▎       | 5/22 [00:03<00:11,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-31T00:00:00, Post ID: 6540ff7c0000000025020b89, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  27%|██▋       | 6/22 [00:04<00:11,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-16T00:00:00, Post ID: 652d2f0e000000001a01540a, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  32%|███▏      | 7/22 [00:04<00:08,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-28T00:00:00, Post ID: 6531fda1000000001f03f950, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  36%|███▋      | 8/22 [00:07<00:16,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-26T00:00:00, Post ID: 653a1632000000001f007a20, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  41%|████      | 9/22 [00:08<00:15,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-11-07T00:00:00, Post ID: 6549b6690000000025008fb1, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  45%|████▌     | 10/22 [00:09<00:13,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-28T00:00:00, Post ID: 653ce06c00000000250099fe, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  50%|█████     | 11/22 [00:10<00:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-11-14T00:00:00, Post ID: 6553966d000000000f02ba6c, Predicted Label: 2, Actual Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  55%|█████▍    | 12/22 [00:10<00:07,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-12-12T00:00:00, Post ID: 657844db000000000801fb87, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  59%|█████▉    | 13/22 [00:10<00:06,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-11-03T00:00:00, Post ID: 6544b4d6000000001f03fcb8, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  64%|██████▎   | 14/22 [00:12<00:07,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-11-08T00:00:00, Post ID: 654b85f7000000003103ed3f, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  68%|██████▊   | 15/22 [00:13<00:07,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-24T00:00:00, Post ID: 6537a2e8000000002202fe5f, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  73%|███████▎  | 16/22 [00:14<00:05,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-12-23T00:00:00, Post ID: 658648370000000009023b33, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  77%|███████▋  | 17/22 [00:15<00:04,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-11-06T00:00:00, Post ID: 6548b4e3000000001d015b26, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  82%|████████▏ | 18/22 [00:16<00:04,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-18T00:00:00, Post ID: 652f8c70000000001c016d99, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  86%|████████▋ | 19/22 [00:17<00:02,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-12-27T00:00:00, Post ID: 658c1ec2000000001000c781, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  91%|█████████ | 20/22 [00:17<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-17T00:00:00, Post ID: 6512dbff000000001e02221e, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  95%|█████████▌| 21/22 [00:18<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-10-27T00:00:00, Post ID: 653bb723000000002201d7fa, Predicted Label: 2, Actual Label: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 22/22 [00:18<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Date: 2024-12-22T00:00:00, Post ID: 65857227000000000901cdb5, Predicted Label: 2, Actual Label: 2\n",
      "Accuracy: 95.45%\n",
      "Test Accuracy: 95.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imagebind import data\n",
    "from imagebind.models import imagebind_model\n",
    "from imagebind.models.imagebind_model import ModalityType\n",
    "import json\n",
    "\n",
    "# Ensure CUDA_LAUNCH_BLOCKING is set for better debugging\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Define file paths\n",
    "data_dir = \"/data1/dxw_data/llm/redbook_final/script_next/\"\n",
    "rawdata_path = os.path.join(data_dir, \"rawdata_20%.csv\")\n",
    "after2monthdata_path = os.path.join(data_dir, \"after2monthdata_20%_with_trend.csv\")\n",
    "image_dir = os.path.join(data_dir, \"data_img_20%\")\n",
    "\n",
    "# Check if files and directories exist\n",
    "assert os.path.exists(rawdata_path), f\"File not found: {rawdata_path}\"\n",
    "assert os.path.exists(after2monthdata_path), f\"File not found: {after2monthdata_path}\"\n",
    "assert os.path.exists(image_dir), f\"Directory not found: {image_dir}\"\n",
    "\n",
    "print(\"All files and directories are verified to exist.\")\n",
    "\n",
    "# Read CSV files\n",
    "rawdata = pd.read_csv(rawdata_path)\n",
    "after2monthdata = pd.read_csv(after2monthdata_path)\n",
    "print(f\"Raw data samples: {len(rawdata)}\")\n",
    "print(f\"After 2 months data samples: {len(after2monthdata)}\")\n",
    "\n",
    "# Convert date columns to standard format\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return parser.parse(date_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "rawdata['post_date'] = rawdata['post_date'].apply(parse_date)\n",
    "rawdata = rawdata.dropna(subset=['post_date'])\n",
    "print(\"Converted post_date to standard format and removed invalid dates.\")\n",
    "\n",
    "# Function to randomly sample a subset of the data\n",
    "def get_subset_indices(data, fraction=0.01):\n",
    "    data_size = len(data)\n",
    "    indices = list(range(data_size))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(fraction * data_size))\n",
    "    return indices[:split]\n",
    "\n",
    "# Random sampling of 1/100th of the data\n",
    "subset_indices = get_subset_indices(rawdata)\n",
    "rawdata = rawdata.iloc[subset_indices]\n",
    "after2monthdata = after2monthdata[after2monthdata['post_id'].isin(rawdata['post_id'])]\n",
    "print(f\"Randomly sampled {len(rawdata)} raw data samples.\")\n",
    "print(f\"Filtered after 2 months data to {len(after2monthdata)} samples.\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_rawdata = rawdata[(rawdata['post_date'].dt.month >= 1) & (rawdata['post_date'].dt.month <= 9)]\n",
    "test_rawdata = rawdata[(rawdata['post_date'].dt.month >= 10) & (rawdata['post_date'].dt.month >= 10)]\n",
    "print(f\"Training raw data samples: {len(train_rawdata)}\")\n",
    "print(f\"Testing raw data samples: {len(test_rawdata)}\")\n",
    "\n",
    "train_after2monthdata = after2monthdata[after2monthdata['post_id'].isin(train_rawdata['post_id'])]\n",
    "test_after2monthdata = after2monthdata[after2monthdata['post_id'].isin(test_rawdata['post_id'])]\n",
    "print(f\"Training after 2 month data samples: {len(train_after2monthdata)}\")\n",
    "print(f\"Testing after 2 month data samples: {len(test_after2monthdata)}\")\n",
    "\n",
    "# Remove non-finite values in the 'trend' column\n",
    "train_after2monthdata = train_after2monthdata.replace([np.inf, -np.inf], np.nan).dropna(subset=['trend'])\n",
    "test_after2monthdata = test_after2monthdata.replace([np.inf, -np.inf], np.nan).dropna(subset=['trend'])\n",
    "print(f\"Training after 2 month data samples after cleaning: {len(train_after2monthdata)}\")\n",
    "print(f\"Testing after 2 month data samples after cleaning: {len(test_after2monthdata)}\")\n",
    "\n",
    "# Ensure that the 'trend' column has correct integer labels\n",
    "train_after2monthdata['trend'] = train_after2monthdata['trend'].astype(int)\n",
    "test_after2monthdata['trend'] = test_after2monthdata['trend'].astype(int)\n",
    "\n",
    "# Define a sliding window function\n",
    "def sliding_window(data, window_size=60):\n",
    "    num_windows = len(data) - window_size + 1\n",
    "    return [data[i:i + window_size] for i in range(num_windows)]\n",
    "\n",
    "# Get sliding windows for training and testing data\n",
    "train_windows = sliding_window(train_rawdata)\n",
    "test_windows = sliding_window(test_rawdata)\n",
    "print(f\"Number of training windows: {len(train_windows)}\")\n",
    "print(f\"Number of testing windows: {len(test_windows)}\")\n",
    "\n",
    "# Custom Dataset Class\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, windows, after2monthdata, image_dir, transform=None, max_images=1, save_test_data=False, test_data_path='test_classification_data.json'):\n",
    "        self.windows = windows\n",
    "        self.after2monthdata = after2monthdata\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.max_images = max_images\n",
    "        self.save_test_data = save_test_data\n",
    "        self.test_data_path = test_data_path\n",
    "        self.data = self._prepare_data()\n",
    "        print(f\"Number of processed samples: {len(self.data)}\")  # Debug information\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        data = []\n",
    "        test_data = []\n",
    "        for window in tqdm(self.windows, desc=\"Processing data\"):\n",
    "            window_data = []\n",
    "            for _, row in window.iterrows():\n",
    "                poster_id = row['poster_id']\n",
    "                post_id = row['post_id']\n",
    "                post_date = row['post_date']\n",
    "                image_files = [f for f in os.listdir(self.image_dir) if f\"{poster_id}_{post_id}\" in f]\n",
    "                images = []\n",
    "                for image_file in image_files[:self.max_images]:\n",
    "                    image_path = os.path.join(self.image_dir, image_file)\n",
    "                    try:\n",
    "                        image = Image.open(image_path).convert('RGB')\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error opening image {image_path}: {e}\")\n",
    "                        continue\n",
    "                    if self.transform:\n",
    "                        image = self.transform(image)\n",
    "                    images.append(image)\n",
    "                while len(images) < self.max_images:\n",
    "                    images.append(torch.zeros((3, 224, 224)))\n",
    "                if images:\n",
    "                    summary = row['summary']\n",
    "                    numerical_list = [float(row['post_comments']), float(row['post_like']), float(row['post_collect'])]\n",
    "                    window_data.append((summary, images, numerical_list))\n",
    "            if window_data:\n",
    "                last_day_post_id = window.iloc[-1]['post_id']\n",
    "                label_data = self.after2monthdata[self.after2monthdata['post_id'] == last_day_post_id]['trend']\n",
    "                if not label_data.empty:\n",
    "                    label = int(label_data.values[0])  # Convert to standard int\n",
    "                    one_hot_label = F.one_hot(torch.tensor(label + 1), num_classes=3)  # -1, 0, 1 -> 0, 1, 2\n",
    "                    data.append((window_data, one_hot_label))\n",
    "                    \n",
    "                    # If saving test data, collect necessary information\n",
    "                    if self.save_test_data:\n",
    "                        test_data.append({\n",
    "                            'post_date': post_date.isoformat(),\n",
    "                            'post_id': str(last_day_post_id),  # Convert to string\n",
    "                            'true_label': label,\n",
    "                            'predicted_label': None  # Will be updated during evaluation\n",
    "                        })\n",
    "                        \n",
    "        if self.save_test_data and test_data:\n",
    "            with open(self.test_data_path, 'w') as f:\n",
    "                json.dump(test_data, f, ensure_ascii=False, indent=4)\n",
    "                \n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        window_data, label = self.data[idx]\n",
    "        summaries, images, numerical_lists = zip(*window_data)\n",
    "        images = [torch.stack(image_set).float() for image_set in images]\n",
    "        return summaries, torch.stack(images), torch.tensor(numerical_lists).float(), label.float()\n",
    "\n",
    "# Image Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "print(\"Image transformations defined.\")\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = MultimodalDataset(train_windows, train_after2monthdata, image_dir, transform=transform)\n",
    "test_dataset = MultimodalDataset(test_windows, test_after2monthdata, image_dir, transform=transform, save_test_data=True, test_data_path='test_classification_data.json')\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in test_loader: {len(test_loader)}\")\n",
    "\n",
    "# Define model components\n",
    "device = \"cuda:4\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load ImageBind model\n",
    "imagebind_model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "imagebind_model.eval()\n",
    "imagebind_model.to(device)\n",
    "print(\"ImageBind model loaded and set to evaluation mode.\")\n",
    "\n",
    "# Define CrossAttentionFusionLSTM model with MLP for numerical features\n",
    "class CrossAttentionFusionLSTM(nn.Module):\n",
    "    def __init__(self, text_embedding_dim, vision_embedding_dim, common_embedding_dim, num_heads, numerical_feature_dim):\n",
    "        super(CrossAttentionFusionLSTM, self).__init__()\n",
    "        self.text_linear = nn.Linear(text_embedding_dim, common_embedding_dim)\n",
    "        self.vision_linear = nn.Linear(vision_embedding_dim, common_embedding_dim)\n",
    "        self.numerical_mlp = nn.Sequential(\n",
    "            nn.Linear(numerical_feature_dim, common_embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(common_embedding_dim, common_embedding_dim)\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=common_embedding_dim, nhead=num_heads), num_layers=2)\n",
    "        self.lstm = nn.LSTM(common_embedding_dim, common_embedding_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(common_embedding_dim, 3)\n",
    "\n",
    "    def forward(self, text_embeddings, vision_embeddings, numerical_embeddings):\n",
    "        text_embeddings = self.text_linear(text_embeddings)\n",
    "        vision_embeddings = self.vision_linear(vision_embeddings)\n",
    "        numerical_embeddings = self.numerical_mlp(numerical_embeddings)\n",
    "        min_len = min(text_embeddings.size(1), vision_embeddings.size(1), numerical_embeddings.size(1))\n",
    "        text_embeddings = text_embeddings[:, :min_len, :]\n",
    "        vision_embeddings = vision_embeddings[:, :min_len, :]\n",
    "        numerical_embeddings = numerical_embeddings[:, :min_len, :]\n",
    "        multimodal_embeddings = torch.cat((text_embeddings, vision_embeddings, numerical_embeddings), dim=1)\n",
    "        multimodal_embeddings = self.transformer_encoder(multimodal_embeddings)\n",
    "        lstm_out, _ = self.lstm(multimodal_embeddings)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "print(\"Model architecture defined.\")\n",
    "\n",
    "# Padding function\n",
    "def pad_embeddings(embeddings, target_length):\n",
    "    if embeddings.size(1) < target_length:\n",
    "        padding = torch.zeros((embeddings.size(0), target_length - embeddings.size(1), embeddings.size(2)), device=embeddings.device)\n",
    "        embeddings = torch.cat((embeddings, padding), dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Get embeddings function\n",
    "def get_embeddings(text_list, image_tensors):\n",
    "    inputs = {\n",
    "        ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n",
    "        ModalityType.VISION: image_tensors.to(device)\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embeddings = imagebind_model(inputs)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Train model function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    log_file = open(\"log.txt\", \"w\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            summaries, images, numerical_lists, labels = batch\n",
    "            images, labels, numerical_lists = images.to(device), labels.to(device), numerical_lists.to(device)\n",
    "            text_embeddings_list = []\n",
    "            vision_embeddings_list = []\n",
    "            for day_summaries, day_images in zip(summaries[0], images[0]):\n",
    "                embeddings = get_embeddings(day_summaries, day_images)\n",
    "                text_embeddings_list.append(embeddings[ModalityType.TEXT])\n",
    "                vision_embeddings_list.append(embeddings[ModalityType.VISION])\n",
    "            \n",
    "            max_len = 60\n",
    "            text_embeddings_list = text_embeddings_list[:max_len]\n",
    "            vision_embeddings_list = vision_embeddings_list[:max_len]\n",
    "            numerical_lists = numerical_lists[:, :max_len, :]\n",
    "\n",
    "            text_embeddings = torch.stack(text_embeddings_list, dim=0)\n",
    "            vision_embeddings = torch.stack(vision_embeddings_list, dim=0)\n",
    "\n",
    "            target_length = max(text_embeddings.size(1), vision_embeddings.size(1), numerical_lists.size(1))\n",
    "            text_embeddings = pad_embeddings(text_embeddings, target_length)\n",
    "            vision_embeddings = pad_embeddings(vision_embeddings, target_length)\n",
    "            numerical_lists = pad_embeddings(numerical_lists, target_length)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(text_embeddings, vision_embeddings, numerical_lists)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        log_file.write(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}\\n')\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}')\n",
    "    log_file.close()\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "text_embedding_dim = 1024\n",
    "vision_embedding_dim = 1024\n",
    "common_embedding_dim = 768\n",
    "num_heads = 8\n",
    "numerical_feature_dim = 3\n",
    "\n",
    "model = CrossAttentionFusionLSTM(text_embedding_dim, vision_embedding_dim, common_embedding_dim, num_heads, numerical_feature_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(\"Model, criterion, and optimizer initialized.\")\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 2\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), os.path.join(data_dir, \"multimodal_model.pth\"))\n",
    "print(\"Model training completed and saved!\")\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, test_data_path):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        test_data = json.load(open(test_data_path))\n",
    "        for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"Evaluating\")):\n",
    "            summaries, images, numerical_lists, labels = batch\n",
    "            images, labels, numerical_lists = images.to(device), labels.to(device), numerical_lists.to(device)\n",
    "            text_embeddings_list = []\n",
    "            vision_embeddings_list = []\n",
    "            for day_summaries, day_images in zip(summaries[0], images[0]):\n",
    "                embeddings = get_embeddings(day_summaries, day_images)\n",
    "                text_embeddings_list.append(embeddings[ModalityType.TEXT])\n",
    "                vision_embeddings_list.append(embeddings[ModalityType.VISION])\n",
    "            \n",
    "            max_len = 60\n",
    "            text_embeddings_list = text_embeddings_list[:max_len]\n",
    "            vision_embeddings_list = vision_embeddings_list[:max_len]\n",
    "            numerical_lists = numerical_lists[:, :max_len, :]\n",
    "\n",
    "            text_embeddings = torch.stack(text_embeddings_list, dim=0)\n",
    "            vision_embeddings = torch.stack(vision_embeddings_list, dim=0)\n",
    "\n",
    "            target_length = max(text_embeddings.size(1), vision_embeddings.size(1), numerical_lists.size(1))\n",
    "            text_embeddings = pad_embeddings(text_embeddings, target_length)\n",
    "            vision_embeddings = pad_embeddings(vision_embeddings, target_length)\n",
    "            numerical_lists = pad_embeddings(numerical_lists, target_length)\n",
    "\n",
    "            outputs = model(text_embeddings, vision_embeddings, numerical_lists)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels_max = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels_max).sum().item()\n",
    "\n",
    "            # Update the predicted labels in the test data and print the details\n",
    "            test_data[batch_idx]['predicted_label'] = int(predicted.item())\n",
    "            print(f\"Post Date: {test_data[batch_idx]['post_date']}, Post ID: {test_data[batch_idx]['post_id']}, Predicted Label: {predicted.item()}, Actual Label: {labels_max.item()}\")\n",
    "        \n",
    "        # Save the updated test data with predicted labels\n",
    "        with open(test_data_path, 'w') as f:\n",
    "            json.dump(test_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    if total > 0:\n",
    "        accuracy = correct / total\n",
    "        print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    else:\n",
    "        accuracy = 0\n",
    "        print(\"No data to evaluate.\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "test_data_path = 'test_classification_data.json'\n",
    "test_accuracy = evaluate_model(model, test_loader, test_data_path)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
