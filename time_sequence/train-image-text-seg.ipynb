{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------更新后的思路---------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items: 100%|██████████| 1703/1703 [04:45<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combined features: 1703\n",
      "Total labels: 1703\n",
      "Total times: 1703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from gensim.models import KeyedVectors\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Paths\n",
    "original_image_path = '/data1/dxw_data/llm/redbook-ture/contentVM-all-img'\n",
    "segmented_image_path = '/data1/dxw_data/llm/redbook-ture/combine_final'\n",
    "text_feature_path = '/data1/dxw_data/llm/redbook-ture/captions.json'\n",
    "sequence_data_path = '/data1/dxw_data/llm/redbook-ture/train_data.json'\n",
    "\n",
    "# Load pretrained ResNet\n",
    "resnet = resnet50(weights=None)\n",
    "resnet.load_state_dict(torch.load('/data1/dxw_data/llm/resnet/resnet50-19c8e357.pth'))\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])  # Remove the classification layer\n",
    "resnet.eval()\n",
    "\n",
    "# Load pretrained Word2Vec model\n",
    "word2vec_path = '/data1/dxw_data/llm/word2vec/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_image_features(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet(image).squeeze().numpy()\n",
    "    return features\n",
    "\n",
    "# Function to extract text features\n",
    "def extract_text_features(caption):\n",
    "    words = caption.split()\n",
    "    word_vectors = []\n",
    "    for word in words:\n",
    "        if word in word2vec_model:\n",
    "            vector = word2vec_model[word]\n",
    "            word_vectors.append(vector)\n",
    "    if not word_vectors:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Define the dataset class\n",
    "class HotnessDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Define the LSTM model class\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take the output of the last time step\n",
    "        out = self.fc(lstm_out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Load sequence data to get the 序号\n",
    "with open(sequence_data_path, 'r') as f:\n",
    "    sequence_data = json.load(f)\n",
    "\n",
    "sequence_map = {int(item['序号']): item for item in sequence_data}\n",
    "\n",
    "# Load JSON file with text features\n",
    "with open(text_feature_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare dataset\n",
    "combined_features = []\n",
    "labels = []\n",
    "times = []\n",
    "\n",
    "for item in tqdm(data, desc=\"Processing items\"):\n",
    "    seq_num = int(item['image'])  # Convert seq_num to integer\n",
    "    text = item['caption']\n",
    "\n",
    "    # Debugging: print seq_num and text\n",
    "    # print(f\"Processing seq_num: {seq_num}, text: {text}\")\n",
    "    segmented_image_path='/data1/dxw_data/llm/redbook-ture/combine_final'\n",
    "    if seq_num in sequence_map:\n",
    "        image_path = os.path.join(original_image_path, f\"{seq_num}.jpg\")\n",
    "        segmented_image_path = os.path.join(segmented_image_path, f\"{seq_num}.png\")\n",
    "\n",
    "        if os.path.exists(image_path) and os.path.exists(segmented_image_path):\n",
    "            # Extract features\n",
    "            image_features = extract_image_features(image_path)\n",
    "            mask_features = extract_image_features(segmented_image_path)\n",
    "            text_features = extract_text_features(text)\n",
    "\n",
    "            # Flatten image features to 1D if necessary\n",
    "            image_features = image_features.flatten()\n",
    "            mask_features = mask_features.flatten()\n",
    "\n",
    "            # Combine features\n",
    "            combined_feature = np.hstack((mask_features, image_features, text_features))\n",
    "            combined_features.append(combined_feature)\n",
    "\n",
    "            labels.append(sequence_map[seq_num]['本产品当前火爆'])\n",
    "            times.append(sequence_map[seq_num]['天数'])\n",
    "        else:\n",
    "            print(f\"Paths do not exist for seq_num: {seq_num}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "combined_features = np.array(combined_features)\n",
    "labels = np.array(labels)\n",
    "times = np.array(times)\n",
    "\n",
    "print(f\"Total combined features: {len(combined_features)}\")\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "print(f\"Total times: {len(times)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.4866\n",
      "Epoch [2/20], Loss: 0.6958\n",
      "Epoch [3/20], Loss: 0.6369\n",
      "Epoch [4/20], Loss: 0.6279\n",
      "Epoch [5/20], Loss: 0.5828\n",
      "Epoch [6/20], Loss: 0.5718\n",
      "Epoch [7/20], Loss: 0.4504\n",
      "Epoch [8/20], Loss: 0.5965\n",
      "Epoch [9/20], Loss: 0.5680\n",
      "Epoch [10/20], Loss: 0.4324\n",
      "Epoch [11/20], Loss: 0.6068\n",
      "Epoch [12/20], Loss: 0.5212\n",
      "Epoch [13/20], Loss: 0.4568\n",
      "Epoch [14/20], Loss: 0.4947\n",
      "Epoch [15/20], Loss: 0.5632\n",
      "Epoch [16/20], Loss: 0.3697\n",
      "Epoch [17/20], Loss: 0.3810\n",
      "Epoch [18/20], Loss: 0.3816\n",
      "Epoch [19/20], Loss: 0.3559\n",
      "Epoch [20/20], Loss: 0.3267\n",
      "Test Accuracy: 61.50%\n"
     ]
    }
   ],
   "source": [
    "# Function to encode time information\n",
    "def encode_time(times, max_time):\n",
    "    times = np.array(times)\n",
    "    sin_time = np.sin(2 * np.pi * times / max_time)\n",
    "    cos_time = np.cos(2 * np.pi * times / max_time)\n",
    "    return np.vstack((sin_time, cos_time)).T\n",
    "\n",
    "encoded_times = encode_time(times, max_time=100)\n",
    "\n",
    "# Split data into training and testing\n",
    "train_indices = np.where(times <= 80)[0]\n",
    "test_indices = np.where(times > 80)[0]\n",
    "\n",
    "time_train = encoded_times[train_indices]\n",
    "time_test = encoded_times[test_indices]\n",
    "\n",
    "# Ensure combined_features is 2D before concatenating\n",
    "if combined_features.ndim == 1:\n",
    "    combined_features = combined_features.reshape(-1, 1)\n",
    "\n",
    "# Concatenate time information with features\n",
    "X_train = np.hstack((combined_features[train_indices], time_train))\n",
    "X_test = np.hstack((combined_features[test_indices], time_test))\n",
    "y_train = labels[train_indices]\n",
    "y_test = labels[test_indices]\n",
    "\n",
    "# Function to create sliding windows for new requirement\n",
    "def create_sliding_windows(X, y, input_window_size, output_window_size):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for i in range(len(X) - input_window_size - output_window_size + 10):\n",
    "        window = X[i:i + input_window_size]\n",
    "        label = y[i + input_window_size + 4:i + input_window_size + 4 + output_window_size]\n",
    "        if len(label) == output_window_size:  # Ensure the label window is complete\n",
    "            features.append(window)\n",
    "            labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "input_window_size = 5  # Using 5 days data to predict\n",
    "output_window_size = 6  # Predicting for 6 days (n+10 to n+15)\n",
    "\n",
    "# Create sliding windows for training and testing\n",
    "X_train, y_train = create_sliding_windows(X_train, y_train, input_window_size, output_window_size)\n",
    "X_test, y_test = create_sliding_windows(X_test, y_test, input_window_size, output_window_size)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = HotnessDataset(X_train, y_train)\n",
    "test_dataset = HotnessDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "output_dim = output_window_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "        total += labels.size(0) * labels.size(1)  # Multiply by output_window_size\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
